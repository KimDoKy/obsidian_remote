---
tags:
  - book
  - linux
---
리눅스는 블록 장치의 성능 향상을 위한 처리는 디바이스 드라이버가 아닌 블록 계층으로 별도로 나눈다.
## 하드 디스크의 특징

HDD: 플래터(platter, 자기 디스크)에 데이터를 자기 정보를 표현을 기록하는 저장 장치
512B or 4KiB의 섹터(sector) 단위로 사용
자기헤드(magnetic head): HDD의 섹터에 데이터를 읽고 쓰는 부품
스윙 암(swing arm): 블래터의 반지름 방향으로 이동할 수 있는 부품
HDD의 데이터 전송 과정
1. 디바이스 드라이버가 데이터를 읽고 쓰는데 필요한 정보를 하드 디스크에 전달. 섹터 번호, 섹터 개수, 접근 종류(읽기/쓰기) 등
2. 스윙 암과 플래터를 움직여서 원하는 섹터 위에 자기 헤드 위치를 맞춤
3. 데이터를 읽고 씀

입출력 성능 개선 방법
- 파일 내부에 동시에 접근할 데이터를 가능한 연속 또는 가까운 영역에 배치함
- 연속한 영역에 접근한다면 여러 번으로 나누는 대신 묶어서 처리

---
## 블록 계층의 기본 기능

블록 계층의 기본 기능은 HDD 특징을 의식해서 생성됨.
대표적인 기능
- 입출력 스케줄러(I/O scheduler)
	- 블록 장치의 접근 요청을 일정 시간 보류했다가 최적화 처리를 위해 디바이스 드라이버에 입출력 요청을 호출함
	- 합치기(merge): 연속된 섹터의 입출력 요청을 하나로 합침
	- 정렬(sort): 연속하지 않은 섹터의 입출력 요청을 섹터 번호 순서로 재정렬
- 미리 읽기(readahead)
	- 블록 장치의 어떤 영역을 읽을 때 가가운 미래에 지금 접근한 영역 근처에 접근 가능성이 높다고 추측하여 미리 읽어서 페이지 캐시에 보관하는 기능
	- 접근하는 패턴이 순차(sequential) 접근이 많은 때 효과적임

---
## 블록 장치의 성능 지표와 측정 방법
### 하나의 프로세스만 입출력을 호출하는 경우
- 스루풋: 단위 시간당 데이터 전송량
	- 크기가 큰 데이터 복사시 중요함
- 레이턴시: 입출력 1회당 걸린 시간으로 저장 장치의 응답 성능을 나타내는 지표
- IOPS(I/O per second): 초당 처리 가능한 입출력 횟수

### 여러 프로세스가 병렬로 입출력을 호출하는 경우
장치의 부하가 적을수록 레이턴시가 짧아지는 경향이 있음
장치가 병렬 입출력을 지원하면 IOPS가 향상될 수 있다.
IOPS가 높을수록 단위 시간당 더 많은 요청을 처리할 수 있다.

### 성능 측정 도구: fio
파일 시스템 성능 측정 도구였지만, 장치 성능 측정 도구로 많이 사용

특징
- 입출력 패턴이나 병렬도, 사용할 입출력 방식(I/O engine)을 세세하게 정할 수 있음
- 레이턴시, 스루풋, IOPS 등 다양한 종류의 성능 정보를 수집 가능

```bash
--test : 각각의 성능 측정 작업명
--filename :  입출력 대상 파일명
--filesize : 입출력 대상 파일 크기
--size : 입출력의 합계 크기
--bz (--blocksize) : 입출력 크기. 합계 입출력 횟수는 --size로 지정한 값을 --bs으로 지정한 값으로 나눈 값
--readwrite : 입출력 종류를 선택
  - read: 순차 읽기
  - write : 순차 쓰기
  - randread : 무작위 읽기
  - randwrite : 무작위 쓰기
--sync=1 : 쓰기 작업을 동기화
--numjobs : 입출력 병렬도. 기본값은 1로 병렬 실행하지 않음
--group_reporting : 병렬도가 2 이상일 때 성능 측정 결과를 각각 출력(기본값)하는 대신 모든 처리를 합쳐서 출력
--output-format : 출력 형식
```

```bash
# 작업명은 test
## 작업은 fio 용어로 성능 측정 대상이 되는 입출력 처리를 식별하기 위한 명칭
# 입출력 패턴은 무작위 읽기
# 파일명이 testdata인 1GiB짜리 파일에서 4KiB씩 합계 4MiB 데이터를 읽어옴
root@01e1478c8494:/app# fio --name test --readwrite=randread --filename testdata --filesize=1G --size=4M --bs=4K --output-format=json
{
  "fio version" : "fio-3.16",
  "timestamp" : 1695276074,
  "timestamp_ms" : 1695276074971,
  "time" : "Thu Sep 21 06:01:14 2023",
  "jobs" : [
    {
      "jobname" : "test",
      ...
      "read" : {
        "io_bytes" : 4194304,
        "io_kbytes" : 4096,
        "bw_bytes" : 10727120, <- 바이트 단위 스루풋
        "bw" : 10475,
        "iops" : 2618.925831, <- IOPS
        ...
       "lat_ns" : {
          "min" : 169666,
          "max" : 2318458,
          "mean" : 379067.191406,   <- 나노초 단위의 평균 레이턴시
          "stddev" : 114464.768719
        },
        ...
     "write" : {
        "io_bytes" : 0,
        "io_kbytes" : 0,
        "bw_bytes" : 0,  <- 바이트 단위 스루풋
        "bw" : 0,
        "iops" : 0.000000,  <- IOPS
        ...
        "lat_ns" : {
          "min" : 0,
          "max" : 0,
          "mean" : 0.000000,  <- 나노초 단위의 평균 레이턴시
          "stddev" : 0.000000
        },
```

---
## 블록 계층이 하드 디스크 성능에 주는 영향

fio를 사용해서 확인

블록 계층의 입출력 스케줄러와 미리 읽기 기능의 유/무효화해서 측정 성능 결과를 비교한다.
- 입출력 스케줄러 무효화: `/sys/block/<device>/queue/scheduler` 파일에 none 기록
- 미리 읽기 무효화: `/sys/block/<device>/queue/read_ahead_kb` 파일에 0을 기록

### 패턴 A 측정 결과
패턴A: 입출력 스케줄러 효과를 확인. 크기가 작은 여러 데이터를 무작위로 쓰기함(레이턴시와 IOPS가 중요)

- 인수
	- filesize: 1GiB
	- group_reporting: -
	- readwrite: randwrite
	- size: 4MiB
	- bs: 4KiB
	- direct: 1 (쓰기 처리가 페이지 캐시로 끝나는 것이 아니라 디스크에도 쓰도록 지정하는 인수)

입출력 스케줄러가 유효일때 IOPS가 높아지고 레이턴시가 줄어든다.
입출력 스케줄러 덕분에 디스크의 입출력 요청이 효율적인 순서로 바뀌었기 때문이다.

### 패턴 B 측정 결과
패턴B: 미리 읽기 효과를 확인. 하나의 대용량 데이터를 순차 읽기(스루풋이 중요)

- 인수
	- readwrite: read
	- size: 128MiB
	- bs: 1MiB

미리 읽기 유효 상태가 무효일 때보다 2배 이상 성능이 높다.
스루풋 결과는 입출력 스케줄러 유무에 거의 영향을 받지 않는다.
B 패턴이 동기화 읽기 방식(디스크에서 데이터를 읽어 오는 작업이 끝난 후 읽기를 하는 방식)이고, 입출력이 병렬화되지 않아 입출력 스케줄러가 활약할 기회(merge나 sort)가 없기 때문이다.

### 기술 혁신에 따른 블록 계층의 변화
SSD는 플래시 메모리를 사용하여 기계적인 동작이 전혀 필요 없어서 읽기 쓰기 모두 전기적인 동작으로 끝나기 때문에 HDD보다 훨씬 빠르게 데이터에 접근할 수 있다.
특히 무작위 접근 성능에서 엄청난 차이가 난다.
하지만 용량단 가격 차이가 많아서 HDD를 사용하는 경우도 많다.

멀티 큐 방식을 도입해서 다수의 CPU에서 동작하는 방법으로 확장성을 햫상시킴
하드웨어 성능이 올라갈수록 블록 계층에서 발생하는 입출력 요청을 일단 모아두었다가 재정렬하는 입출력 스케줄러의 처리가 문제가 되는데, 최적화에서 오는 속도 향상보다 늘어난 레이턴시 때문에 결과적으로 느려지는 현상이 증가했다.
때문에 우분투 20.04는 NVMe SSD의 입출력 스케줄러를 완전히 무시하는 것이 기본값이다.

---
## 블록 계층이 NVMe SSD 성능에 미치는 영향
### 패턴 A 측정 결과
입출력 스케줄러의 유/무효화에 따라 IOPS, 레이턴시를 비교

입출력 스케줄러가 무효인 경우 병렬도가 낮은 구간에서 IOPS가 더 높다.

레이턴시
병렬도가 낮으면 무효화쪽이 더 짧은 편
병렬도가 높아지면 우효한 편이 더 짧은 편

NVMe SSD와 같은 고속 저장 장치는 입출력 요청을 일단 모아두는 입출력 스케줄러의 구조에서 발생하는 처리 비용이 HDD에 비해 상대적으로 높기 때문이다.

### 패턴 B 측정 결과
HDD와 마찬가지로 미리 읽기를 사용하면 스루풋이 높아진다. HDD보다 훨씬 큰 단위이다.
입출력 스케줄러는 오히려 유휴 상태일 때 성능이 더 떨어진다.
NVMe SSD처럼 빠른 저장 장치라면 입출력 스케줄러 처리 비용이 장점보다 단점이 상대적으로 많기 때문이다.

---
실제 시스템이라면 스프트웨어, 네트워크 같은 다른 구성 요소의 성능도 고려해야 한다.

---
#linux 